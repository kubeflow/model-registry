package catalog

import (
	"regexp"
	"strings"
	"testing"

	"github.com/DATA-DOG/go-sqlmock"
	catalogfilter "github.com/kubeflow/model-registry/catalog/internal/db/filter"
	"github.com/kubeflow/model-registry/internal/db/filter"
	"github.com/kubeflow/model-registry/internal/db/schema"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"gorm.io/driver/postgres"
	"gorm.io/gorm"
	"gorm.io/gorm/logger"
)

// SQLCapture captures SQL queries and arguments generated by GORM
type SQLCapture struct {
	Queries []string
	Args    [][]any
}

// setupMockGORMWithCapture creates a mock PostgreSQL GORM DB that captures SQL queries
func setupMockGORMWithCapture(t *testing.T) (*gorm.DB, sqlmock.Sqlmock, *SQLCapture) {
	mockDB, mock, err := sqlmock.New(sqlmock.QueryMatcherOption(sqlmock.QueryMatcherRegexp))
	require.NoError(t, err)

	// Configure GORM with PostgreSQL and the mock database
	dialector := postgres.New(postgres.Config{
		Conn:                 mockDB,
		PreferSimpleProtocol: true, // Disable prepared statements for easier testing
	})

	db, err := gorm.Open(dialector, &gorm.Config{
		Logger: logger.Default.LogMode(logger.Silent),
		DryRun: true, // Enable DryRun mode to capture SQL without executing
	})
	require.NoError(t, err)

	capture := &SQLCapture{
		Queries: make([]string, 0),
		Args:    make([][]any, 0),
	}

	return db, mock, capture
}

// captureQuerySQL builds the query and captures the generated SQL using DryRun mode
func captureQuerySQL(t *testing.T, db *gorm.DB, query *gorm.DB) (string, []any) {
	// Execute the query in dry run mode to generate SQL
	stmt := query.Find(&[]schema.Context{}).Statement
	if stmt != nil {
		return stmt.SQL.String(), stmt.Vars
	}

	return "", []any{}
}

func TestFilterQueryToSQLGeneration(t *testing.T) {
	tests := []struct {
		name         string
		filterQuery  string
		expectedSQL  []string // SQL fragments that should be present
		expectedArgs []any    // Expected query arguments (flattened)
		shouldError  bool
		description  string
	}{
		{
			name:        "Simple name equality filter",
			filterQuery: `name = "test-model"`,
			expectedSQL: []string{
				`"Context".name = $`,
			},
			expectedArgs: []any{"test-model"},
			description:  "Core property filters should query the main entity table directly with PostgreSQL quoting",
		},
		{
			name:        "Custom property string filter",
			filterQuery: `framework.string_value = "PyTorch"`,
			expectedSQL: []string{
				"JOIN",
				`"ContextProperty"`,
				"prop_1",
				`prop_1.context_id = "Context".id`,
				`prop_1.name = $`,
				`prop_1.string_value = $`,
			},
			expectedArgs: []any{"framework", "PyTorch"},
			description:  "Custom properties should require JOIN with property table using PostgreSQL syntax",
		},
		{
			name:        "Custom property with type inference",
			filterQuery: `accuracy > 0.95`,
			expectedSQL: []string{
				"JOIN",
				`"ContextProperty"`,
				"prop_1",
				`prop_1.context_id = "Context".id`,
				`prop_1.name = $`,
				`prop_1.double_value > $`,
			},
			expectedArgs: []any{"accuracy", 0.95},
			description:  "Numeric values should infer double_value type",
		},
		{
			name:        "LIKE pattern matching",
			filterQuery: `name LIKE "%model%"`,
			expectedSQL: []string{
				`"Context".name LIKE $`,
			},
			expectedArgs: []any{"%model%"},
			description:  "LIKE operator should be preserved in SQL",
		},
		{
			name:        "Case-insensitive ILIKE (PostgreSQL native)",
			filterQuery: `name ILIKE "%MODEL%"`,
			expectedSQL: []string{
				`"Context".name ILIKE $`,
			},
			expectedArgs: []any{"%MODEL%"},
			description:  "ILIKE should use PostgreSQL's native ILIKE operator",
		},
		{
			name:        "IN clause with multiple values",
			filterQuery: `license IN ('MIT','Apache-2.0','GPL')`,
			expectedSQL: []string{
				"JOIN",
				`"ContextProperty"`,
				"prop_1",
				`prop_1.name = $`,
				`prop_1.string_value IN ($3,$4,$5)`,
			},
			expectedArgs: []any{"license", "MIT", "Apache-2.0", "GPL"},
			description:  "IN clause should generate proper PostgreSQL placeholder syntax",
		},
		{
			name:        "Multiple filters with AND",
			filterQuery: `provider.string_value = "HuggingFace" AND framework.string_value = "PyTorch"`,
			expectedSQL: []string{
				"JOIN",
				`"ContextProperty"`,
				"prop_1",
				`prop_1.name = $`,
				`prop_1.string_value = $`,
				"prop_2",
				`prop_2.name = $`,
				`prop_2.string_value = $`,
			},
			expectedArgs: []any{"provider", "HuggingFace", "framework", "PyTorch"},
			description:  "Multiple custom properties should create separate JOINs",
		},
		{
			name:        "OR condition with parentheses",
			filterQuery: `(framework.string_value = "PyTorch" OR framework.string_value = "TensorFlow")`,
			expectedSQL: []string{
				"EXISTS",
				`"ContextProperty"`,
				`"ContextProperty".context_id = "Context".id`,
				`"ContextProperty".name = $`,
				"OR",
			},
			expectedArgs: []any{"framework", "PyTorch", "framework", "TensorFlow"},
			description:  "OR conditions should use EXISTS subqueries to avoid JOIN complexities",
		},
		{
			name:        "Mixed core and custom properties",
			filterQuery: `name = "test-model" AND accuracy.double_value > 0.9`,
			expectedSQL: []string{
				`"Context".name = $`,
				"JOIN",
				`"ContextProperty"`,
				"prop_1",
				`prop_1.name = $`,
				`prop_1.double_value > $`,
			},
			expectedArgs: []any{"test-model", "accuracy", 0.9},
			description:  "Mixed property types should combine direct and JOIN conditions",
		},
		{
			name:        "Numeric comparisons",
			filterQuery: `accuracy.double_value >= 0.95 AND priority.int_value < 10`,
			expectedSQL: []string{
				`prop_1.double_value >= $`,
				`prop_2.int_value < $`,
			},
			expectedArgs: []any{"accuracy", 0.95, "priority", int64(10)},
			description:  "Numeric comparisons should preserve operator types",
		},
		{
			name:        "Boolean property filter",
			filterQuery: `is_validated.bool_value = true`,
			expectedSQL: []string{
				`prop_1.bool_value = $`,
			},
			expectedArgs: []any{"is_validated", true},
			description:  "Boolean values should be handled correctly",
		},
		{
			name:        "String with quotes and special characters",
			filterQuery: `description = "Model's \"best\" version (v1.0)"`,
			expectedSQL: []string{
				"JOIN",
				`"ContextProperty"`,
				`prop_1.string_value = $`,
			},
			expectedArgs: []any{"description", `Model's "best" version (v1.0)`},
			description:  "Special characters should be properly escaped and parameterized",
		},
		{
			name:        "Invalid syntax should error",
			filterQuery: `invalid syntax here`,
			shouldError: true,
			description: "Malformed queries should return parsing errors",
		},
		{
			name:        "Unmatched parentheses should error",
			filterQuery: `name = "test" AND (framework = "pytorch"`,
			shouldError: true,
			description: "Syntax errors should be caught during parsing",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			// Parse the filterQuery
			filterExpr, err := filter.Parse(tt.filterQuery)

			if tt.shouldError {
				assert.Error(t, err, "Expected parsing error for: %s", tt.filterQuery)
				return
			}

			require.NoError(t, err, "Failed to parse filterQuery: %s", tt.filterQuery)
			require.NotNil(t, filterExpr, "FilterExpression should not be nil")

			// Create a query builder for catalog models (Context entities)
			queryBuilder := filter.NewQueryBuilderForRestEntity(
				filter.RestEntityType(catalogfilter.RestEntityCatalogModel),
				catalogfilter.NewCatalogEntityMappings(), // Use catalog-specific mappings
			)

			// Create mock PostgreSQL GORM DB to capture generated SQL
			mockDB, sqlMock, _ := setupMockGORMWithCapture(t)
			defer func() {
				if err := sqlMock.ExpectationsWereMet(); err != nil {
					t.Logf("SQL mock expectations not met: %v", err)
				}
			}()

			// Build the query - this will generate SQL but not execute it
			baseQuery := mockDB.Model(&schema.Context{}).Where("type_id = ?", 1)
			resultQuery := queryBuilder.BuildQuery(baseQuery, filterExpr)

			// Capture the generated SQL using DryRun mode
			generatedSQL, queryArgs := captureQuerySQL(t, mockDB, resultQuery)
			require.NotEmpty(t, generatedSQL, "Should have captured generated SQL")

			t.Logf("Generated SQL: %s", generatedSQL)
			t.Logf("Query args: %v", queryArgs)

			for _, expectedFragment := range tt.expectedSQL {
				assert.Contains(t, generatedSQL, expectedFragment,
					"Generated SQL should contain fragment: %s\nFull SQL: %s",
					expectedFragment, generatedSQL)
			}

			// Verify arguments if specified
			if len(tt.expectedArgs) > 0 {
				// Check that all expected args are present (order may vary due to JOINs)
				for _, expectedArg := range tt.expectedArgs {
					found := false
					for _, actualArg := range queryArgs {
						if actualArg == expectedArg {
							found = true
							break
						}
					}
					assert.True(t, found, "Expected argument %v not found in actual args: %v",
						expectedArg, queryArgs)
				}
			}

			t.Logf("✅ %s", tt.description)
		})
	}
}

func TestPostgreSQLSpecificFeatures(t *testing.T) {
	tests := []struct {
		name        string
		filterQuery string
		expectedSQL []string
		description string
	}{
		{
			name:        "ILIKE with PostgreSQL native support",
			filterQuery: `name ILIKE "%pytorch%"`,
			expectedSQL: []string{
				`"Context".name ILIKE $`,
			},
			description: "PostgreSQL should use native ILIKE instead of UPPER() workaround",
		},
		{
			name:        "JSON property query (if supported)",
			filterQuery: `metadata.string_value = "{\"version\": \"1.0\"}"`,
			expectedSQL: []string{
				`prop_1.string_value = $`,
			},
			description: "JSON strings should be properly parameterized",
		},
		{
			name:        "Unicode content",
			filterQuery: `description.string_value = "模型描述"`,
			expectedSQL: []string{
				`prop_1.string_value = $`,
			},
			description: "Unicode characters should be handled correctly",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			// Parse and build query
			filterExpr, err := filter.Parse(tt.filterQuery)
			require.NoError(t, err)

			queryBuilder := filter.NewQueryBuilderForRestEntity(
				filter.RestEntityType(catalogfilter.RestEntityCatalogModel),
				catalogfilter.NewCatalogEntityMappings(),
			)

			mockDB, sqlMock, _ := setupMockGORMWithCapture(t)
			defer func() {
				if err := sqlMock.ExpectationsWereMet(); err != nil {
					t.Logf("SQL mock expectations not met: %v", err)
				}
			}()

			baseQuery := mockDB.Model(&schema.Context{}).Where("type_id = ?", 1)
			resultQuery := queryBuilder.BuildQuery(baseQuery, filterExpr)

			// Capture the generated SQL using DryRun mode
			generatedSQL, queryArgs := captureQuerySQL(t, mockDB, resultQuery)
			if generatedSQL != "" {
				t.Logf("Generated SQL: %s", generatedSQL)
				t.Logf("Query args: %v", queryArgs)

				for _, expectedFragment := range tt.expectedSQL {
					assert.Contains(t, generatedSQL, expectedFragment,
						"Generated SQL should contain: %s", expectedFragment)
				}
			}

			t.Logf("✅ %s", tt.description)
		})
	}
}

func TestFilterQuerySQLInjectionPrevention(t *testing.T) {
	tests := []struct {
		name        string
		filterQuery string
		description string
	}{
		{
			name:        "SQL injection in string value",
			filterQuery: `name = "'; DROP TABLE \"Context\"; --"`,
			description: "SQL injection attempts should be safely parameterized",
		},
		{
			name:        "SQL injection in property name",
			filterQuery: `malicious'; DROP TABLE "Context"; -- = "value"`,
			description: "Property names should be validated and escaped",
		},
		{
			name:        "SQL injection via ILIKE pattern",
			filterQuery: `name ILIKE "'; DROP TABLE \"Context\"; --"`,
			description: "ILIKE patterns should be parameterized",
		},
		{
			name:        "PostgreSQL-specific injection attempts",
			filterQuery: `name = "'; CREATE FUNCTION malicious() RETURNS void AS $$ DROP TABLE \"Context\"; $$ LANGUAGE sql; --"`,
			description: "PostgreSQL function injection should be prevented",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			// Parse the filterQuery
			filterExpr, err := filter.Parse(tt.filterQuery)

			// Some injection attempts might fail at parse time, which is fine
			if err != nil {
				t.Logf("Query rejected at parse time (good): %v", err)
				return
			}

			if filterExpr == nil {
				return
			}

			// Create query builder
			queryBuilder := filter.NewQueryBuilderForRestEntity(
				filter.RestEntityType(catalogfilter.RestEntityCatalogModel),
				catalogfilter.NewCatalogEntityMappings(),
			)

			// Create mock PostgreSQL GORM DB
			mockDB, sqlMock, _ := setupMockGORMWithCapture(t)
			defer func() {
				if err := sqlMock.ExpectationsWereMet(); err != nil {
					t.Logf("SQL mock expectations not met: %v", err)
				}
			}()

			// Build the query
			baseQuery := mockDB.Model(&schema.Context{}).Where("type_id = ?", 1)
			resultQuery := queryBuilder.BuildQuery(baseQuery, filterExpr)

			// Capture the generated SQL using DryRun mode
			generatedSQL, _ := captureQuerySQL(t, mockDB, resultQuery)

			// Verify that dangerous SQL is not present in the generated query
			if generatedSQL != "" {

				// Check for dangerous SQL patterns
				dangerousPatterns := []string{
					"DROP TABLE",
					"DELETE FROM",
					"INSERT INTO",
					"UPDATE.*SET",
					"CREATE FUNCTION",
					"--",
					";",
				}

				for _, pattern := range dangerousPatterns {
					matched, _ := regexp.MatchString(pattern, generatedSQL)
					assert.False(t, matched,
						"Generated SQL should not contain dangerous pattern '%s': %s",
						pattern, generatedSQL)
				}

				// Verify that all user input is parameterized (using $ placeholders)
				// PostgreSQL uses $1, $2, etc. for parameters
				parameterizedCount := len(regexp.MustCompile(`\$\d+`).FindAllString(generatedSQL, -1))
				assert.Greater(t, parameterizedCount, 0,
					"Query should use parameterized queries with $ placeholders")

				t.Logf("✅ %s - SQL safely parameterized with %d parameters", tt.description, parameterizedCount)
				t.Logf("Generated SQL: %s", generatedSQL)
			}
		})
	}
}

func TestComplexFilterQueryGeneration(t *testing.T) {
	tests := []struct {
		name           string
		filterQuery    string
		expectedJoins  int // Expected number of property table joins
		expectedExists int // Expected number of EXISTS subqueries
		description    string
	}{
		{
			name:          "Multiple custom properties with AND",
			filterQuery:   `framework.string_value = "PyTorch" AND license.string_value = "MIT" AND provider.string_value = "HuggingFace"`,
			expectedJoins: 3,
			description:   "Each custom property should create a separate JOIN",
		},
		{
			name:           "Complex OR with parentheses",
			filterQuery:    `(framework.string_value = "PyTorch" OR framework.string_value = "TensorFlow") AND license.string_value = "MIT"`,
			expectedExists: 2, // OR condition uses 2 EXISTS (one for each OR branch)
			expectedJoins:  1, // AND condition uses JOIN
			description:    "OR conditions should use EXISTS, AND conditions use JOINs",
		},
		{
			name:        "Nested logical conditions",
			filterQuery: `((accuracy.double_value > 0.9 AND f1_score.double_value > 0.85) OR (precision.double_value > 0.95)) AND framework.string_value = "PyTorch"`,
			description: "Deeply nested conditions should be handled correctly",
		},
		{
			name:        "Mixed property types and operators",
			filterQuery: `name ILIKE "%model%" AND accuracy.double_value >= 0.9 AND is_public.bool_value = true AND tags.string_value IN ('nlp','computer-vision')`,
			description: "Should handle core properties, custom properties, and different data types with PostgreSQL syntax",
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			// Parse the filterQuery
			filterExpr, err := filter.Parse(tt.filterQuery)
			require.NoError(t, err, "Failed to parse filterQuery: %s", tt.filterQuery)
			require.NotNil(t, filterExpr)

			// Create query builder
			queryBuilder := filter.NewQueryBuilderForRestEntity(
				filter.RestEntityType(catalogfilter.RestEntityCatalogModel),
				catalogfilter.NewCatalogEntityMappings(),
			)

			// Create mock PostgreSQL GORM DB
			mockDB, sqlMock, _ := setupMockGORMWithCapture(t)
			defer func() {
				if err := sqlMock.ExpectationsWereMet(); err != nil {
					t.Logf("SQL mock expectations not met: %v", err)
				}
			}()

			// Build the query
			baseQuery := mockDB.Model(&schema.Context{}).Where("type_id = ?", 1)
			resultQuery := queryBuilder.BuildQuery(baseQuery, filterExpr)

			// Capture the generated SQL using DryRun mode
			generatedSQL, _ := captureQuerySQL(t, mockDB, resultQuery)

			// Analyze the generated SQL
			if generatedSQL != "" {
				t.Logf("Generated SQL: %s", generatedSQL)

				// Count JOINs if expected
				if tt.expectedJoins > 0 {
					joinCount := strings.Count(generatedSQL, "JOIN")
					assert.Equal(t, tt.expectedJoins, joinCount,
						"Expected %d JOINs, found %d in: %s",
						tt.expectedJoins, joinCount, generatedSQL)
				}

				// Count EXISTS if expected
				if tt.expectedExists > 0 {
					existsCount := strings.Count(generatedSQL, "EXISTS")
					assert.Equal(t, tt.expectedExists, existsCount,
						"Expected %d EXISTS clauses, found %d in: %s",
						tt.expectedExists, existsCount, generatedSQL)
				}

				// Verify PostgreSQL-specific features
				assert.Contains(t, generatedSQL, `"`, "Should use PostgreSQL identifier quoting")

				// Verify parameterized queries
				paramCount := len(regexp.MustCompile(`\$\d+`).FindAllString(generatedSQL, -1))
				assert.Greater(t, paramCount, 0, "Should use PostgreSQL parameter placeholders")

				// Verify query is valid SQL (no syntax errors)
				assert.NotContains(t, generatedSQL, "ERROR")
				assert.NotContains(t, generatedSQL, "INVALID")
			}

			t.Logf("✅ %s", tt.description)
		})
	}
}
